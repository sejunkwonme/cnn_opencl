#pragma warning(disable:4996)
#include "cnn.h"
#include <time.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <stdio.h>
#include <CL/cl.h>
#include "layershape.h"
#include "cnnSeqFunc.h"

extern const char* CLASS_NAME[];

#define CHECK_ERROR(err) \
    if (err != CL_SUCCESS) { \
        printf("[%s:%d] OpenCL error %d\n", __FILE__, __LINE__, err); \
        exit(EXIT_FAILURE); \
    }


void print_images(float* images, int num_of_image, int ch) {
    for (int img = 0; img < num_of_image; img++) {
        printf("Image %d:\n", img + 1);
        // 각 이미지의 시작 포인터 계산
        float* image_ptr = images + img * 32 * 32 * 3;

        for (int c = 0; c < 3; c++) { // 채널 반복 (0: R, 1: G, 2: B)
            printf("  Channel %d:\n", c + 1);
            // 각 채널의 시작 포인터 계산
            float* channel_ptr = image_ptr + c * 32 * 32;

            for (int row = 0; row < 32; row++) {
                for (int col = 0; col < 32; col++) {
                    // 현재 픽셀 값 접근
                    float value = *(channel_ptr + row * 32 + col);
                    printf("%5.2f ", value);
                }
                printf("\n");
            }
            printf("\n");
        }
        printf("\n");
    }
}


char* get_source_code(const char* file_name, size_t * len);
void build_error(cl_program program, cl_device_id device, cl_int err);

cl_int err;
cl_platform_id platform;
cl_device_id device;
cl_context context;
cl_command_queue queue;

size_t kernel_source_size;
cl_program program;

cl_kernel conv;
cl_kernel maxPooling;
cl_kernel fcLayer;

cl_mem images_buffer; // 추론할 입력 이미지 모두 들어가는 버퍼
cl_mem layer_buffer[21]; // 결과 레이어 버퍼
cl_mem w_buffer[21]; // 가중치 버퍼
cl_mem b_buffer[21]; // 편향 버퍼

float* layer[21]; // 시작주소 계산용 변수
float* w[21];
float* b[21];

float* result; // 결과 담을 변수

void cnn_init(float* images, float* network, int num_of_image) {
    // OPENCL CNN 프로그램을 초기화

    // Platform ID
    err = err = clGetPlatformIDs(1, &platform, NULL);
    CHECK_ERROR(err);

    // Device ID
    err = clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 1, &device, NULL);
    CHECK_ERROR(err);

    // Create Context
    context = clCreateContext(NULL, 1, &device, NULL, NULL, &err);
    CHECK_ERROR(err);

    // Create Command Queue
    queue = clCreateCommandQueueWithProperties(context, device, 0, &err);
    CHECK_ERROR(err);

    // Create Program Object
    size_t kernel_source_size;
    char* kernel_source = get_source_code("../../CNN_OPENCL/kernel.cl", &kernel_source_size);
    program = clCreateProgramWithSource(context, 1, (const char**)&kernel_source, &kernel_source_size, &err);
    CHECK_ERROR(err);

    // Build Program
    err = clBuildProgram(program, 1, &device, "", NULL, NULL);
    build_error(program, device, err);
    CHECK_ERROR(err);

    // create kernel object
    // Conv,Maxpooling, FullyConnected를 따로 구현
    conv = clCreateKernel(program, "conv", &err);
    CHECK_ERROR(err);
    maxPooling = clCreateKernel(program, "maxPooling", &err);
    CHECK_ERROR(err);
    fcLayer = clCreateKernel(program, "fcLayer", &err);
    CHECK_ERROR(err);

    // 이미지 버퍼 생성
    // 이미지 버퍼에 한 번에 3천개의 이미지를 할당할 수는 있지만, 
    // 할당가능한 최대 메모리보다 더 커지지 않기 위해 분할했던 num_of_image만큼만 할당한다.
    images_buffer = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * 32 * 32 * 3 * num_of_image, NULL, &err);
    CHECK_ERROR(err);

    // 필터, 바이어스 버퍼 생성, 필터 바이아스는 이미지마다 다 같다.
    // link weights and biases to network
    for (int i = 0; i < 17; ++i) {
        if (i == 2 || i == 5 || i == 9 || i == 13) i++;	// pooling layer has no weights and biases
        w_buffer[i] = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * 3 * 3 * INPUT_DIM[i] * OUTPUT_DIM[i], NULL, &err);
        CHECK_ERROR(err);
        b_buffer[i] = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * OUTPUT_DIM[i], NULL, &err);
        CHECK_ERROR(err);
    }
    for (int i = 18; i < 21; ++i) {
        w_buffer[i] = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * INPUT_DIM[i] * OUTPUT_DIM[i], NULL, &err);
        CHECK_ERROR(err);
        b_buffer[i] = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * OUTPUT_DIM[i], NULL, &err);
        CHECK_ERROR(err);
    }

    // num_of_image에 따라 레이어 버퍼 생성 병렬처리 할때는 3000개 만큼 이미지를 담아야 한다
    // 테스트 할 때는 이미지 10개를 처리할 예정
    // 순차처리 코드에서는 Layer 한개가 이미지 한장이므로 여기 크기에 10을 곱해줘야 한다
    for (int i = 0; i < 21; i++) {
        layer_buffer[i] = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * NBYN[i] * NBYN[i] * OUTPUT_DIM[i] * num_of_image, NULL, &err);
        CHECK_ERROR(err);
    }
}

void enqueueConvolution(cl_mem input, cl_mem output, int i, int num_of_image) {
    err = clSetKernelArg(conv, 0, sizeof(cl_mem), &input);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 1, sizeof(cl_mem), &w_buffer[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 2, sizeof(cl_mem), &b_buffer[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 3, sizeof(cl_mem), &output);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 4, sizeof(int), &INPUT_DIM[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 5, sizeof(int), &OUTPUT_DIM[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 6, sizeof(int), &NBYN[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 7, sizeof(float) * INPUT_DIM[i] * 9, NULL);
    CHECK_ERROR(err);
    err = clSetKernelArg(conv, 8, sizeof(float) * INPUT_DIM[i] * 9, NULL);
    CHECK_ERROR(err);

    // 한 이미지를 처리하기 위한 출력채널 크기 * 이미지 개수(10)
    size_t global_work_size[3] = {
        // work item 1개가 곱하기 9번을 순차실행한다 x 이것이 가로 세로번 이루어진다
        static_cast<size_t>(1 * NBYN[i] * NBYN[i]), // 글로벌 워크 아이템 개수 패딩연산이 필요하므로 원래 크기대로 간다
        static_cast<size_t>(INPUT_DIM[i] * OUTPUT_DIM[i]), // 입력채널 개수 x  출력채널 개수 해야한다 이래야 그룹사이즈가 나눠떨어진다
        static_cast<size_t>(num_of_image) // 배치차원 (한번에 들어가는 이미지 개수)
    };

    // 그룹사이즈.
    size_t local_work_size[3] = {
        1, INPUT_DIM[i], 1
    };

    err = clEnqueueNDRangeKernel(queue, conv, 3, NULL, global_work_size, local_work_size, 0, NULL, NULL);
    CHECK_ERROR(err);
}

void enqueueMaxPooling(cl_mem input, cl_mem output, int i, int num_of_image) {
    err = clSetKernelArg(maxPooling, 0, sizeof(cl_mem), &input);
    CHECK_ERROR(err);
    err = clSetKernelArg(maxPooling, 1, sizeof(cl_mem), &output);
    CHECK_ERROR(err);
    err = clSetKernelArg(maxPooling, 2, sizeof(int), &INPUT_DIM[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(maxPooling, 3, sizeof(int), &NBYN[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(maxPooling, 4, sizeof(float) * 4, NULL);
    CHECK_ERROR(err);

    // 한 이미지를 처리하기 위한 출력채널 크기 * 이미지 개수(10)
    size_t global_work_size[3] = {
        // work item 1개가 곱하기 9번을 순차실행한다 x 이것이 가로 세로번 이루어진다
        static_cast<size_t>(1 * NBYN[i] * NBYN[i]), // 글로벌 워크 아이템 개수 패딩연산이 필요하므로 원래 크기대로 간다
        static_cast<size_t>(INPUT_DIM[i]), // 입력채널 개수 x  출력채널 개수 해야한다 이래야 그룹사이즈가 나눠떨어진다
        static_cast<size_t>(num_of_image) // 배치차원 (한번에 들어가는 이미지 개수)
    };

    // 그룹사이즈.
    size_t local_work_size[3] = {
        1, 1, 1
    };

    err = clEnqueueNDRangeKernel(queue, maxPooling, 3, NULL, global_work_size, local_work_size, 0, NULL, NULL);
    CHECK_ERROR(err);
}

void enqueuefcLayer(cl_mem input, cl_mem output, int i, int num_of_image) {
    err = clSetKernelArg(fcLayer, 0, sizeof(cl_mem), &input);
    CHECK_ERROR(err);
    err = clSetKernelArg(fcLayer, 1, sizeof(cl_mem), &output);
    CHECK_ERROR(err);
    err = clSetKernelArg(fcLayer, 2, sizeof(cl_mem), &w_buffer[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(fcLayer, 3, sizeof(cl_mem), &b_buffer[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(fcLayer, 4, sizeof(int), &INPUT_DIM[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(fcLayer, 5, sizeof(int), &OUTPUT_DIM[i]);
    CHECK_ERROR(err);
    err = clSetKernelArg(fcLayer, 6, sizeof(int), &NBYN[i]);
    CHECK_ERROR(err);

    // 한 이미지를 처리하기 위한 출력채널 크기 * 이미지 개수(10)
    size_t global_work_size[3] = {
        // work item 1개가 곱하기 9번을 순차실행한다 x 이것이 가로 세로번 이루어진다
        static_cast<size_t>(1 * OUTPUT_DIM[i]), // 글로벌 워크 아이템 개수 패딩연산이 필요하므로 원래 크기대로 간다
        static_cast<size_t>(INPUT_DIM[i]), // 입력채널 개수 x  출력채널 개수 해야한다 이래야 그룹사이즈가 나눠떨어진다
        static_cast<size_t>(num_of_image) // 배치차원 (한번에 들어가는 이미지 개수)
    };

    // 그룹사이즈.
    size_t local_work_size[3] = {
        1, INPUT_DIM[i], 1
    };

    err = clEnqueueNDRangeKernel(queue, fcLayer, 3, NULL, global_work_size, local_work_size, 0, NULL, NULL);
    CHECK_ERROR(err);
}

void cnn(float* images, float* network, int* labels, float* confidences, int num_of_image) {
    //cnn_init 을 통해 디바이스 프로그램을 초기화하고 실행한다
	cnn_init(images, network, num_of_image);

	// link weights and biases to network (for seqcnn)
	int offset = 0;
	for (int i = 0; i < 17; ++i) {
		if (i == 2 || i == 5 || i == 9 || i == 13) i++;	// pooling layer has no weights and biases
		w[i] = network + offset;
		offset += 3 * 3 * INPUT_DIM[i] * OUTPUT_DIM[i];
		b[i] = network + offset;
		offset += OUTPUT_DIM[i];
	}
	for (int i = 18; i < 21; ++i) {
		w[i] = network + offset;
		offset += INPUT_DIM[i] * OUTPUT_DIM[i];
		b[i] = network + offset;
		offset += OUTPUT_DIM[i];
	}

	// allocate memory for layer
    // 순차처리 코드에서는 레이어 하나당 이미지 한장이다
    // 병렬처리 할때는 배치 하나의 크기가 한번에 돌아가므로 그만큼 더 곱해주어야 한다
	for (int i = 0; i < 21; ++i) {
		layer[i] = (float*)malloc(sizeof(float) * OUTPUT_DIM[i] * NBYN[i] * NBYN[i] * num_of_image);
		if (layer[i] == NULL) {
			perror("malloc error");
    	}
	}

    for (int i = 0; i < 17; ++i) {
        if (i == 2 || i == 5 || i == 9 || i == 13) i++;	// pooling layer has no weights and biases
        err = clEnqueueWriteBuffer(queue, w_buffer[i], CL_TRUE, 0, sizeof(float) * 3 * 3 * INPUT_DIM[i] * OUTPUT_DIM[i], w[i], 0, NULL, NULL);
        CHECK_ERROR(err);
        err = clEnqueueWriteBuffer(queue, b_buffer[i], CL_TRUE, 0, sizeof(float) * OUTPUT_DIM[i], b[i], 0, NULL, NULL);
        CHECK_ERROR(err);
    }

    for (int i = 18; i < 21; ++i) {
        err = clEnqueueWriteBuffer(queue, w_buffer[i], CL_TRUE, 0, sizeof(float) * INPUT_DIM[i] * OUTPUT_DIM[i], w[i], 0, NULL, NULL);
        CHECK_ERROR(err);
        err = clEnqueueWriteBuffer(queue, b_buffer[i], CL_TRUE, 0, sizeof(float) * OUTPUT_DIM[i], b[i], 0, NULL, NULL);
        CHECK_ERROR(err);
    }

	time_t start, end;
	start = clock();

    err = clEnqueueWriteBuffer(queue, images_buffer, CL_FALSE, 0, sizeof(float) * 32 * 32 * 3 * num_of_image, images, 0, NULL, NULL);
    CHECK_ERROR(err);
    enqueueConvolution(images_buffer, layer_buffer[0], 0, num_of_image);
    enqueueConvolution(layer_buffer[0], layer_buffer[1], 1, num_of_image);
    enqueueMaxPooling(layer_buffer[1], layer_buffer[2], 2, num_of_image);
    
    enqueueConvolution(layer_buffer[2], layer_buffer[3], 3, num_of_image);
    enqueueConvolution(layer_buffer[3], layer_buffer[4], 4, num_of_image);
    enqueueMaxPooling(layer_buffer[4], layer_buffer[5], 5, num_of_image);

    enqueueConvolution(layer_buffer[5], layer_buffer[6], 6, num_of_image);
    enqueueConvolution(layer_buffer[6], layer_buffer[7], 7, num_of_image);
    enqueueConvolution(layer_buffer[7], layer_buffer[8], 8, num_of_image);
    enqueueMaxPooling(layer_buffer[8], layer_buffer[9], 9, num_of_image);

    enqueueConvolution(layer_buffer[9], layer_buffer[10], 10, num_of_image);
    enqueueConvolution(layer_buffer[10], layer_buffer[11], 11, num_of_image);
    enqueueConvolution(layer_buffer[11], layer_buffer[12], 12, num_of_image);
    enqueueMaxPooling(layer_buffer[12], layer_buffer[13], 13, num_of_image);

    enqueueConvolution(layer_buffer[13], layer_buffer[14], 14, num_of_image);
    enqueueConvolution(layer_buffer[14], layer_buffer[15], 15, num_of_image);
    enqueueConvolution(layer_buffer[15], layer_buffer[16], 16, num_of_image);
    enqueueMaxPooling(layer_buffer[16], layer_buffer[17], 17, num_of_image);

    enqueuefcLayer(layer_buffer[17], layer_buffer[18], 18, num_of_image);
    enqueuefcLayer(layer_buffer[18], layer_buffer[19], 19, num_of_image);
    enqueuefcLayer(layer_buffer[19], layer_buffer[20], 20, num_of_image);
    
    err = clEnqueueReadBuffer(queue, layer_buffer[20], CL_TRUE, 0, sizeof(float) * OUTPUT_DIM[20] * NBYN[20] * NBYN[20] * num_of_image, layer[20], 0, NULL, NULL);
    CHECK_ERROR(err);
    int i = 0;
    for (int i = 0; i < num_of_image; i++) {
        softmax(layer[20] + i * 10, 10);
    }
    //softmax(layer[20], 10);
        
    int imgindex = 0;
    for (int* iter = labels; iter < labels + num_of_image; iter++) {
        *iter = find_max(layer[20] + imgindex * 10, 10);
        imgindex++;
    }

    imgindex = 0;
    for (float* iter = confidences; iter < confidences + num_of_image; iter++) {
        *iter = *((layer[20]) + (imgindex * 10) + labels[imgindex]);
        imgindex++;
    }
    //labels[0] = find_max(layer[20], 10);
    //confidences[0] = layer[20][labels[0]];

	end = clock();
	printf("Elapsed time: %.2f sec\n", (double)(end - start) / CLK_TCK);
}

char* get_source_code(const char* file_name, size_t* len) {
    FILE* file = fopen(file_name, "rb");
    if (file == NULL) {
        printf("[%s:%d] Failed to open %s\n", __FILE__, __LINE__, file_name);
        exit(EXIT_FAILURE);
    }

    fseek(file, 0, SEEK_END);
    size_t length = (size_t)ftell(file);
    rewind(file);

    char* source_code = (char*)malloc(length + 1);
    fread(source_code, length, 1, file);
    source_code[length] = '\0';
    fclose(file);
    *len = length;

    return source_code;
}

void build_error(cl_program program, cl_device_id device, cl_int err) {
    if (err == CL_BUILD_PROGRAM_FAILURE) {
        size_t log_size;
        char* log;

        err = clGetProgramBuildInfo(program, device, CL_PROGRAM_BUILD_LOG, 0, NULL, &log_size);
        CHECK_ERROR(err);

        log = (char*)malloc(log_size + 1);
        err = clGetProgramBuildInfo(program, device, CL_PROGRAM_BUILD_LOG, log_size, log, NULL);
        CHECK_ERROR(err);

        log[log_size] = '\0';
        printf("Compiler error:\n%s\n", log);
        free(log);
        exit(0);
    };
}